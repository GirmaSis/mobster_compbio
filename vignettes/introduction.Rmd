---
title: "Vignette for mobster"
author: "Giulio Caravagna"
date: "September 2019"
institute: "Institute for Cancer Research"
email: "giulio.caravagna@icr.ac.uk"
output: rmarkdown::github_document
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Table of contents
1. [Generating a random MOBSTER dataset](#generation)
2. [Fitting a dataset](#fitting)
3. [Selecting alternative best models](#alternative)
4. [Another paragraph](#paragraph2)

This vignette describes the basic usage of the MOBSTER R package for subclonal deconvolution in cancer. 

The package is available at [Github](https://github.com/caravagn/MOBSTER). 


```{r, message=FALSE, warning=F}
library(mobster)
```

## Generating a MOBSTER dataset <a name="generation"></a>

The input data must be formatted as an object of class `data.frame` (or, `tibble`) with at least one columun named `VAF` whose values are numerical, and no `NA` values are present. If a dataset has at least this column, then it can be processed with MOBSTER; the output object will contain a copy of the input data. 

> Example datasets and fits are released as `data` inside the package, and are accessible as usual via `data("xxx", package = 'mobster')` where `xxx` is the name of the dataset to load. See the package manual for a list of available data.


In this vignette we sample a random dataset using the `random_dataset` function, which has different parameters to customize the data creation. Shortly, you can set 

* the number of samples (mutations) and Beta components (subclones) to generate;
* constraint on the size of the components, the position and spread of the Beta means, and the variance of the Beta components.
* set the seed to fix the process.

In this example we fix the seed and the parameter `Beta_variance_scaling`, which  affects the variance of the Beta(s). Because the variance is sampled as `U[0,1]` and scaled by this value, values on the order of `1000` give low variance, while `100` represents a dataset with quite some dispersion (compared to a putative Binomial generative model).

```{r, message=FALSE, warning=F}
dataset = random_dataset(seed = 123, Beta_variance_scaling = 100)
```

A list with 3 components is returned, which you can access to see the actual data, the sampled parameters of the generative model, and a plot of the data. 

> This function uses function `rdbpmm` , a the sampler from the density function of the Dirchlet Beta Pareto Mixture Model (DBPMM) object that is implemented in MOBSTER -- see `?rdbpmm` and `?ddbpmm`.

```{r, fig.width=4, fig.height=3}
# Data, in the MOBSTER input format with a "VAF" column.
print(dataset$data)

# The generated model contains the parameters of the Beta components (a and b),
# the shape and scale of the tail, and the mixing proportion. 
print(dataset$model)

# A plot object (ggplot) is available where each data-point is coloured by 
# its generative mixture component. The vertical lines annontate the means of
# the sampled Beta distributions.
print(dataset$plot)
```

## Fitting a dataset<a name="fitting"></a>

Function `mobster_fit` is the main function to fit a MOBSTER model. This function implements a model selection routine that, by default, scores the models with the *reduced Incomplete Classification Likelihood* (reICL). reICL is a variant to the popular BIC score which uses the entropy of the latent variables of the model; the reICL formulation uses a particular version of this score, as discussed in the main MOBSTER paper. 

>The fits are computed  computed exploiting the [easypar](https://github.com/caravagn/easypar) package, which allows easy parallel run of R functions.

This function has several parameters that allow one customizing the type of fit, the optimization task etc. Here we sample 1 fit per configuration of parameters, and set the optimization to stop when the variation between the mixing proportions and the likelihood is below `epsilon = 1e-4` (usually, one would use `epsilon = 1e-10` but with this value the compilation of this vignette is faster).

```{r, fig.width=4, fig.height=3}
# Fit by MOBSTER
fit = mobster_fit(dataset$data, samples = 1, epsilon = 1e-4, parallel = TRUE)
```
As a result, a call of `mobster_fit` will return a list with:

* the best fit, accessible as named object `fit$best`;
* a `fit$runs` list that contains the top fits (ranked by score), the object available as `best` will match the head of this list, `fit$runs`;
* and a `fit$fits.table` that summarises the scores for each one of the runs.

The `fits.table` reports also other scores for the model fits, which include AIC, BIC, ICL the entropy and the likelihood of the model. Each fit object (`best` or any object stored in `runs`) is from class `dbpmm`. This class provides S3 objects for print and plot of a MOBSTER model
```{r, fig.width=4, fig.height=3}
# Print the best model, as well as the first 3 models in the runs list
print(fit$best)

print(fit$runs[[1]]) # same as best
print(fit$runs[[2]])
print(fit$runs[[3]])
```
The simplest visualization for MOBSTER's fits is a coloured histogram, where colours represent clustering assignments, overlaid to the model density. By default MOBSTER names Beta clusters according to the decreasing order of their mean; so `C1` is always the label of the cluster with highest mean, etc. The basic plot shows, mirrored on the y-axis, the percentage of sum-of-squared-error (SSE) as a function of the input VAF (which is termed `Observed Frequency` in the x-axis). The plot caption annotates some information about the fitting.

```{r, fig.width=5, fig.height=4}
# Plot the best model
plot(fit$best)
```
A comparative plot between the fit and the simulated data can be assembled with `ggpubr` function, which can take two `ggplot` objects and assemble them (an alternative function is `plot_grid` from the `cowplot` package).
```{r, eval=FALSE}
# Not run
figure = ggarrange(dataset$plot, plot(fit$best), ncol = 2)
print(figure)
```
Hard clustering assignments are computed and can be accessed with function `Clusters`, the function also allows imposing a minimum cutoff to the reponsibilities of the mutations (if a mutation's maximum responsibility is below the cutoff, its assignment will be `NA`). Note that the return tibble is a copy of the input, with the new  `cluster` column, plus a set of columns for the latent variables in MOBSTER (the clustering reponsibilities).
```{r}
# Assign mutations with at least 80% of probability mass to their maximum responsibility
clusters = Clusters(fit$best, cutoff_assignment = .8)
print(clusters)
```

A set of plots is available to inspect further details of a fit. For example,

* the latent variables can also be visualized as heatmap;
* the mixing proportions as barplot;
* the trace of the negative log-likelihood (NLL) can be inspected;
* and the initial condition of the fit can be plot as density.
```{r, fig.width=2.5, fig.height=5}
# Assign mutations with at least 80% of probability mass to their maximum responsibility
plot_latent_variables(fit$best, cutoff_assignment = .8)
```

```{r, fig.width=3, fig.height=3}
# Mixing proportions
plot_mixing_proportions(fit$best)

# NLL trace
plot_NLL(fit$best)

# Plot the initial condition of the fit
plot_init(fit$best)
```


### Selecting alternative best models<a name="alternative"></a>

Alternative models are returned function `mobster_fit`, and can be easly visualized.


```{r, fig.width=15, fig.height=4, message=FALSE, warning=FALSE}
require(ggpubr)

# Figure assembly
figure = ggarrange(
  plot(fit$runs[[1]]),
  plot(fit$runs[[2]]),
  plot(fit$runs[[3]]),
  ncol = 3, nrow = 1
)

print(figure)
```
The table reportin the scores can be visualised, and everal plots are available to inspect model selection.
```{r, fig.width=15, fig.height=4, message=FALSE, warning=FALSE}
print(fit$fits.table)
```

One can plot of the sum of squared error (SSE) between the fit density and the data (binned with bins of size 0.01), for several solutions at once. This measure can represent a sort of goodness of fit statistics.

```{r, fig.width=3, fig.height=6}
# Goodness of fit (SSE), for the top 3 fits.
plot_gofit(fit, TOP = 3)
```

The scores can also be compared graphically. Running `plot_fit_scores` all the computed scoring functions (BIC, AIC, ICL and reICL) are shown, which helps understanding if the best model with the default score (reICL) is the best also according to the other scores. In this graphics the red dot represents the best model according to each score.
```{r, fig.width=4, fig.height=4}
plot_fit_scores(fit)
```


These functions can be all wrapped by a call to `plot_model_selection` which plots the above summary statistics and the fits for each one of a set of top models (change the parameter `TOP` to select how many plots should be computed).
```{r, fig.width=9, fig.height=9, message=FALSE, warning=FALSE, eval=FALSE}
# Not run
plot_model_selection(fit, TOP = 5)
```
## Bootstrapping a model<a name="bootstrap"></a>

There are two types of bootstrap functions available in MOBSTER: parametric and nonparametric. The former samples data from the model, and re-runs the fits; the latter re-samples the data (with repetitions), and re-runs the fits. In both cases a distribution of the parameter fits can be approximated, and in the case of nonparametric bootstrap also probability of clustering together two mutations can be computed.

To show this, we sample and fit smaller dataset
```{r eval=T, fig.height=4, fig.width=8, message=FALSE, warning=FALSE}
dataset = random_dataset(N = 250, seed = 1)
fit = mobster_fit(dataset$data)

# Composition with cowplot
figure = cowplot::plot_grid(dataset$plot, plot(fit$best), ncol = 2, align = 'h')
print(figure)
```


```{r, fig.width=9, fig.height=9, message=FALSE, warning=FALSE, eval=T}
# Run 10 nonparametric bootstraps, and compute the bootstrapped statistics.
# The returned object contains also the list of bootstrap resamples, and the fits.
bootstrap_results = mobster_bootstrap(fit$best,
                                      bootstrap = 'nonparametric',
                                      n.resamples = 10,
                                      epsilon = 1e-4,   # forwarded to mobster_fit
                                      K = c(1, 2)       # forwarded to mobster_fit, test only models with 1 or 2 Betas
                                      )

# Statistics can be computed with a MOBSTER function.
bootstrap_statistics = bootstrapped_statistics(fit$best, bootstrap_results = bootstrap_results)
```


Bootstrapping, one can compute the model probability across re-samples
```{r, fig.width=2, fig.height=3}
# Show the table and plot it at barplot
print(bootstrap_statistics$bootstrap_model)
plot_bootstrap_model_frequency(bootstrap_results, bootstrap_statistics)
```


Similarly, one can compute the parameter probabilitiesacross re-samples
```{r, fig.width=12, fig.height=3}
# Show the table
print(bootstrap_statistics$bootstrap_statistics)

# Plot the mixing proportions
mplot = plot_bootstrap_mixing_proportions(
  fit$best, 
  bootstrap_results = bootstrap_results, 
  bootstrap_statistics = bootstrap_statistics)

# Plot the tail parameters
tplot = plot_bootstrap_tail(fit$best, bootstrap_results = bootstrap_results, bootstrap_statistics = bootstrap_statistics)

# Plot the Beta parameters
bplot = plot_bootstrap_Beta(fit$best, bootstrap_results = bootstrap_results, bootstrap_statistics = bootstrap_statistics)

ggarrange(
  mplot,
  tplot,
  bplot,
  ncol = 3, nrow = 1,
  widths = c(.7, 1, 1)
)
```

In the end, because this is a nonparametric bootstrap run, the co-clustering probability can be plot as well
```{r, fig.width=5.6, fig.height=5}
plot_bootstrap_coclustering(fit$best, bootstrap_results = bootstrap_results, bootstrap_statistics = bootstrap_statistics)
```